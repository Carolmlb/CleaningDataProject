##Put functions in a list
list(set = set, get = get,
setinverse = setinverse
getinverse = getinverse)
}
##
## Matrix is created; cacheSolve function will calculate the inverse using "solve"
## function and cache the result. If user uses cacheSolve on same matrix for
## which the inverse was already calculated, the cached result is used rather
## than recalculating.
##
cacheSolve <- function(x, ...) {
## Check state of the inverse of the matrix to see if already calculated
inv <- x$getinverse()
## If not NULL, return cached value
if(!is.null(inv)) {
##Write message to inform user of cached source of value
message("Matrix retrieved from cache")
return(inv)
}
## If inverse is NULL, get the matrix data, calculate and cache inverse
data <-x$get()
inv <- solve(data, ...)
x$setinverse(inv)
inv
}
x <- matrix(1:4, nrow=2, ncol=2)
m <- makeCacheMatrix(x)
## Functions: makeCacheMatrix and cacheSolve
##
## Programmer: Carolmlb (Carol Roffer)
## Source Programmer: rdpeng
## Course: Johns Hopkins, Data Science: R Programming (October 2015)
##
## This file contains two functions; makeCacheMatrix and cacheSolve. The pair
## of functions cache the inverse of a matrix.
##
## makeCacheMatrix creates a special "matrix" object that can cache its inverse.
## A list of four functions is created (see Assignment 2 sample using vector)
## 1. set the value of the matrix (set)
## 2. get the value of the matrix (get)
## 3. set the value of inverse of matrix (setinverse)
## 4. get the value of inverse of the matrix (getinverse)
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- (function(inverse) inv <<- inverse)
getinverse <- function() inv
##Put functions in a list
list(set = set, get = get,
setinverse = setinverse
getinverse = getinverse)
}
##
## Matrix is created; cacheSolve function will calculate the inverse using "solve"
## function and cache the result. If user uses cacheSolve on same matrix for
## which the inverse was already calculated, the cached result is used rather
## than recalculating.
##
cacheSolve <- function(x, ...) {
## Check state of the inverse of the matrix to see if already calculated
inv <- x$getinverse()
## If not NULL, return cached value
if(!is.null(inv)) {
##Write message to inform user of cached source of value
message("Matrix retrieved from cache")
return(inv)
}
## If inverse is NULL, get the matrix data, calculate and cache inverse
data <-x$get()
inv <- solve(data, ...)
x$setinverse(inv)
inv
}
## Functions: makeCacheMatrix and cacheSolve
##
## Programmer: Carolmlb (Carol Roffer)
## Source Programmer: rdpeng
## Course: Johns Hopkins, Data Science: R Programming (October 2015)
##
## This file contains two functions; makeCacheMatrix and cacheSolve. The pair
## of functions cache the inverse of a matrix.
##
## makeCacheMatrix creates a special "matrix" object that can cache its inverse.
## A list of four functions is created (see Assignment 2 sample using vector)
## 1. set the value of the matrix (set)
## 2. get the value of the matrix (get)
## 3. set the value of inverse of matrix (setinverse)
## 4. get the value of inverse of the matrix (getinverse)
##
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- (function(inverse) inv <<- inverse)
getinverse <- function() inv
##Put functions in a list
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
##
## Matrix is created; cacheSolve function will calculate the inverse using "solve"
## function and cache the result. If user uses cacheSolve on same matrix for
## which the inverse was already calculated, the cached result is used rather
## than recalculating.
##
cacheSolve <- function(x, ...) {
## Check state of the inverse of the matrix to see if already calculated
inv <- x$getinverse()
## If not NULL, return cached value
if(!is.null(inv)) {
##Write message to inform user of cached source of value
message("Matrix retrieved from cache")
return(inv)
}
## If inverse is NULL, get the matrix data, calculate and cache inverse
data <-x$get()
inv <- solve(data, ...)
x$setinverse(inv)
inv
}
x <- matrix(1:4, nrow=2, ncol=2)
m <- makeCacheMatrix(x)
s <- cacheSolve(m)
print(s)
s2 <- cacheSolve(m)
print(s2)
set.seed(1)
rpois(5,2)
?rnorm
?dpois
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
?system.time
?qpois
library(swirl)
ls()
rm(list=ls())
swirl()
?vapply
vapply(flags,unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags,class, character(1))
?tapply
table(flag$landmass)
table(flags$landmass)
table(flags?animate)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6,4, replace=TRUE)
sample(1:6,4, replace=TRUE)
sample(1:20)
sample(1:20, 10)
letters
LETTERS
sample(LETTERS)
flips <- sample(c(0,1),100, replace=TRUE, prob=(0.3,0.7))
flips <- sample(c(0,1),100, replace=TRUE, prob=c(0.3,0.7))
flips
sum(flips)
?rbinom
rbinom(1, size=100, prob=0.7)
flips2 <- rbinom(100, size=1, prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, 100, 25)
rpois(5, 10)
my_pois <- replicate(100, rpois(5,10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(sys.time())
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
?strptime
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist, y = cars$speed)
?plot
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", y = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main = "My Plot")
?plot
plot(cars, sub = "My Plot Subtitle")
?par
par(col = 2)
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data(mtcars)
play()
str(cars)
str(mtcars)
?mtcars
nxt()
?boxplot
boxplot(mpg ~ cycl, data = mtcars)
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
source("submitscript3.R")
submit()
insall.packages('RMySQL',type='source')
install.packages('RMySQL',type='source')
library("RMySQL")
hg19 <- dbConnect(MySQL(),user="genome",db="hg19",host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
dbDisconnect(hg19)
?require
librarhy(dplyr)
install.packages("dplyr")
setwd("C:/Coursera/Data Science/DS3_Work/Quiz3")
if (!file.exists("data")) {
dir.create("data")
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/getdata-data-ss06hid.csv")
communitySurvey <- read.csv("./data/getdata-data-Fss06.csv")
head(communitySurvey)
str(communitySurvey)
communitySurvey <- read.csv("./data/getdata-data-ss06hid.csv")
head(communitySurvey)
str(communitySurvey)
?which
dt <- data.table(read.csv("./data/getdata-data-ss06hid.csv"))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
agricultureLogical
library(data.table)
dt <- data.table(read.csv("./data/getdata-data-ss06hid.csv"))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
agricultureLogical
which(agricultureLogical[1:3])
which(agricultureLogical)[1:3]
which(agricultureLogical)
?download.file
library(jpeg)
if (!file.exists("data")) {
dir.create("data")
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./data/"jeff.jpg,mode="wb")
picture <- readJPEG("./data/jeff.jpg", native = TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./data/jeff.jpg",mode="wb")
picture <- readJPEG("./data/jeff.jpg", native = TRUE)
quantile(picture, probs = c(0.3, 0.8))
if (!file.exists("data")) {
dir.create("data")
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/getdata%2Fdata%2FGDP.csv")
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl2, destfile = "./data/getdata%2Fdata%2FEDSTATS_Country.csv")
FGDP <- read.csv("./data/getdata%2Fdata%2FGDP.csv")
FEDSTATS <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
names(FGDP)
str(FGDP)
summary(FGDP)
str(FEDSTATS)
head(FGDP, 3)
head(FGDP)
names(FGDP)
names(FEDSTATS)
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv")
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
head(fgdp)
head(fedstats)
mergedData=as.data.frame(merge(fgdpclean,fedstats,by.x="X",by.y="CountryCode"))
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv")
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
X=CountryCode
names(fgdp)
names(fedstats)
fgdpclean<-fgdp[5:194,]
mergedData=as.data.frame(merge(fgdpclean,fedstats,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
nrow(fgdp)
fgdp <- datatable(read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4, nrows 326)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
names(fgdp)
names(fedstats)
fgdp <- datatable(read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
fgdp <- datatable(read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4))
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
combined <- merge(fgdp, fedstats, by.x = "X", by.y = "CountryCode", sort=TRUE)
View(combined)
?merge
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
combined <- merge(fgdp, fedstats,  all = TRUE, by.x = "X", by.y = "CountryCode")
sum(!is.na(unique(combined$rankingGDP)))
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
combined <- merge(fgdp, fedstats, by.x = "X", by.y = "CountryCode")
nrows(combined)
nrow(combined)
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
combined <- merge(fgdp, fedstats, all = TRUE, by.x = "X", by.y = "CountryCode")
dt <- data.table(combined)
sum(!is.na(unique(dt$rankingGDP)))
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
combined <- merge(fgdp, fedstats, all = TRUE, by.x = "X", by.y = "CountryCode")
combined[with(combined, order(-X.1))]
nrow(fgdp)
head (fgdp)
tail(fgdp)
fgdp <- read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4)
fedstats <- read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv")
fgdp <- [X!= ""]
fgdp <- data.table(read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4))
fedstats <- data.table(read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv"))
fgdp <- [X!= ""]
fgdp <- [X != ""]
fgdp <- [X != "",]
fgdp <- [fgdp$X != "",]
fgdp <- fgdp[X != "",]
nrow(fgdp)
fgdp <- fgdp[, list(X, X.1, X.3, X.4)]
setnames(fgdp, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
combined <- merge(fgdp, fedstats, all=TRUE, by = c("CountryCode"))
sum(!is.na(unique(combined$rankingGDP)))
combined <- merge(fgdp, fedstats, by = c("CountryCode"))
sum(!is.na(unique(combined$rankingGDP)))
combined[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp)][13]
combined[order(rankingGDP, decreasing = TRUE), ]
combined[order(rankingGDP, decreasing = TRUE), ][1]
combined[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp][1]
combined[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp)] [1]
combined[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp)] [1:14]
fgdp <- data.table(read.csv("./data/getdata%2Fdata%2FGDP.csv", skip =4, nrows =215))
fedstats <- data.table(read.csv("./data/getdata%2Fdata%2FEDSTATS_Country.csv"))
fgdp <- fgdp[X != "",]
fgdp <- fgdp[, list(X, X.1, X.3, X.4)]
setnames(fgdp, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
combined <- merge(fgdp, fedstats, by = c("CountryCode"))
sum(!is.na(unique(combined$rankingGDP)))
combined[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y,
rankingGDP, gdp)] [1:14]
combined[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(combined$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
combined$quantileGDP <- combined(combined$rankingGDP, breaks = breaks)
combined[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
breaks <- quantile(combined$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
combined$quantileGDP <- cut(combined$rankingGDP, breaks = breaks)
combined[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
library(reshape2)
## Getting and Cleaning Data Course Project
## Carol Roffer  -  November 2015
##
##  This script, run_analysis.R,  does the following:
##  1. Merges the training and the test sets to create one data set.
##  2. Extracts only the measurements on the mean and standard deviation for each measurement.
##  3. Uses descriptive activity names to name the activities in the data set
##  4. Appropriately labels the data set with descriptive variable names.
##  5. From the data set in step 4, creates a second, independent tidy data set
##     with the average of each variable for each activity and each subject
## Assumes the zip file has been downloaded already
library(reshape2)
zipfile <- "getdata-projectfiles-UCI HAR Dataset.zip"
if (!file.exists("UCI HAR Dataset")) {
unzip(zipfile)
}
# Load activity labels + features
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
features <- read.table("UCI HAR Dataset/features.txt")
features[,2] <- as.character(features[,2])
# Extract only the data on mean and standard deviation
featuresWanted <- grep(".*mean.*|.*std.*", features[,2])
featuresWanted.names <- features[featuresWanted,2]
featuresWanted.names = gsub('-mean', 'Mean', featuresWanted.names)
featuresWanted.names = gsub('-std', 'Std', featuresWanted.names)
featuresWanted.names <- gsub('[-()]', '', featuresWanted.names)
# Load the datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")[featuresWanted]
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
train <- cbind(trainSubjects, trainActivities, train)
test <- read.table("UCI HAR Dataset/test/X_test.txt")[featuresWanted]
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
test <- cbind(testSubjects, testActivities, test)
# merge datasets and add labels
allData <- rbind(train, test)
colnames(allData) <- c("subject", "activity", featuresWanted.names)
# turn activities & subjects into factors
allData$activity <- factor(allData$activity, levels = activityLabels[,1], labels = activityLabels[,2])
allData$subject <- as.factor(allData$subject)
allData.melted <- melt(allData, id = c("subject", "activity"))
allData.mean <- dcast(allData.melted, subject + activity ~ variable, mean)
write.table(allData.mean, "tidy.txt", row.names = FALSE, quote = FALSE)
setwd("C:/Coursera/Data Science/DS3_Work")
setwd("C:/gitrepos/CleaningDataProject")
library(reshape2)
zipfile <- "getdata-projectfiles-UCI HAR Dataset.zip"
if (!file.exists("UCI HAR Dataset")) {
unzip(zipfile)
}
# Load activity labels + features
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
features <- read.table("UCI HAR Dataset/features.txt")
features[,2] <- as.character(features[,2])
# Extract only the data on mean and standard deviation
featuresWanted <- grep(".*mean.*|.*std.*", features[,2])
featuresWanted.names <- features[featuresWanted,2]
featuresWanted.names = gsub('-mean', 'Mean', featuresWanted.names)
featuresWanted.names = gsub('-std', 'Std', featuresWanted.names)
featuresWanted.names <- gsub('[-()]', '', featuresWanted.names)
# Load the datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")[featuresWanted]
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
train <- cbind(trainSubjects, trainActivities, train)
test <- read.table("UCI HAR Dataset/test/X_test.txt")[featuresWanted]
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
test <- cbind(testSubjects, testActivities, test)
# merge datasets and add labels
allData <- rbind(train, test)
colnames(allData) <- c("subject", "activity", featuresWanted.names)
# turn activities & subjects into factors
allData$activity <- factor(allData$activity, levels = activityLabels[,1], labels = activityLabels[,2])
allData$subject <- as.factor(allData$subject)
allData.melted <- melt(allData, id = c("subject", "activity"))
allData.mean <- dcast(allData.melted, subject + activity ~ variable, mean)
write.table(allData.mean, "tidy.txt", row.names = FALSE, quote = FALSE)
?names
